{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import sys\n",
    "import json\n",
    "import itertools\n",
    "from IPython.display import Image\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import sqlite3 as sql\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chisquare\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, precision_recall_curve, roc_curve, auc, mean_squared_error\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class of functions that pull data from sourses and store the dataframes in a json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Json():\n",
    "    global json_storage\n",
    "    d={}\n",
    "    s=json.dumps(d)\n",
    "    json_storage = json.loads(s)\n",
    "    def __init__(self, df_name):\n",
    "        self.df_name=df_name\n",
    "    def csv(self, url):\n",
    "        if url[0]=='r':\n",
    "            download = requests.get(url).content\n",
    "            df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n",
    "            df=pd.DataFrame(df)\n",
    "            json_storage[self.df_name]=[url,df]\n",
    "        else:\n",
    "            df=pd.read_csv(url)\n",
    "            df=pd.DataFrame(df)\n",
    "            json_storage[self.df_name]=[url,df]\n",
    "        return(df)\n",
    "    def excel(self, e, s):\n",
    "        df=pd.read_excel(e, s)\n",
    "        json_storage[self.df_name]=[e,df]\n",
    "        return(df)\n",
    "    def web_scrape(self, u, c):\n",
    "        url = requests.get(u).text\n",
    "        soup = BeautifulSoup(url,'lxml')\n",
    "        table = soup.find('table')\n",
    "        table_rows = table.find_all('tr')\n",
    "        l = []\n",
    "        for tr in table_rows:\n",
    "            td = tr.find_all('td')\n",
    "            row = [tr.text for tr in td]\n",
    "            l.append(row)\n",
    "        df=pd.DataFrame(l, columns=c)\n",
    "        json_storage[self.df_name]=[u,df]\n",
    "        return(df)\n",
    "    def file(self, f):\n",
    "        file = open(f, \"r\")\n",
    "        read=file.read()\n",
    "        json_storage[self.df_name]=read\n",
    "        return(read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class of graphing functions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graph:\n",
    "    def choropleth(self, d, location, lm, c, af, s, t):\n",
    "        fig = px.choropleth(d , locations = location, locationmode = lm, color = c\n",
    "                    ,animation_frame=af, scope=s)\n",
    "        fig.update_layout(title_text = t)\n",
    "        fig.show()\n",
    "    def bar_chart(self, x, y, t, x2, y2):\n",
    "        fig, ax = plt.subplots(figsize=(50,150))   \n",
    "        width=.25\n",
    "        ax.barh(x, y, width, color='red')\n",
    "        for i, v in enumerate(y):\n",
    "            ax.text(v, i, str(v), color='blue')\n",
    "        plt.rcParams.update({'font.size': 20})\n",
    "        plt.title(t, fontsize=40)\n",
    "        plt.xlabel(x2, fontsize=30)\n",
    "        plt.ylabel(y2, fontsize=30)      \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that prints summary statistics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc(x):\n",
    "    print(x.name)\n",
    "    print('Count:', x.count())\n",
    "    print('Mean:', x.mean())\n",
    "    print('Standard Deviation:', x.std())\n",
    "    print('Min:', x.min())\n",
    "    print(\"Q1 quantile: \", np.quantile(x, .25)) \n",
    "    print(\"Q2 quantile: \", np.quantile(x, .5)) \n",
    "    print(\"Q3 quantile: \", np.quantile(x, .75))\n",
    "    print('Max:', x.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that creates a dataframe of covid-19 totals and prints the totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(d, dd1, name, dd2, ddd):\n",
    "        for i in d:\n",
    "            p=dd1.loc[dd1[name]==f'{i}']['Population']\n",
    "            p=int(p)\n",
    "            c=dd1.loc[dd1[name]==f'{i}']['Total_Cases']\n",
    "            c=int(c)\n",
    "            d=dd1.loc[dd1[name]==f'{i}']['Total_Deaths']\n",
    "            d=int(d)\n",
    "            r=dd1.loc[dd1[name]==f'{i}']['Total_Recovered']\n",
    "            r=int(r)\n",
    "            t=dd1.loc[dd1[name]==f'{i}']['Total_Tests']\n",
    "            t=int(t)\n",
    "            a=dd1.loc[dd1[name]==f'{i}']['Active_Cases']\n",
    "            a=int(a)\n",
    "            if name=='Country':\n",
    "                try:\n",
    "                    v=dd2.loc[dd2[name]==f'{i}'].iloc[[-1]]['total_vaccinations']\n",
    "                except:\n",
    "                    v=0\n",
    "            elif name == 'State':\n",
    "                try:\n",
    "                    v=dd2.loc[dd2[name]==f'{i}']['Vaccines_Administered']\n",
    "                except:\n",
    "                    v=0\n",
    "            v=int(v)\n",
    "            try:\n",
    "                tp=(t/p)*100\n",
    "                if tp>=100:\n",
    "                    tp=99.99\n",
    "            except:\n",
    "                tp=0\n",
    "            try:\n",
    "                ct=(c/t)*100\n",
    "                if ct>=100:\n",
    "                    ct=99.99\n",
    "            except:\n",
    "                ct=0\n",
    "            try:\n",
    "                rc=(r/c)*100\n",
    "                if rc>=100:\n",
    "                    rc=99.99\n",
    "            except:\n",
    "                rc=0\n",
    "            try:\n",
    "                dc=(d/c)*100\n",
    "                if dc>=100:\n",
    "                    dc=99.99\n",
    "            except:\n",
    "                dc=0\n",
    "            try:\n",
    "                vp=(v/p)*100\n",
    "                if vp>=100:\n",
    "                    vp=99.99\n",
    "            except:\n",
    "                vp=0\n",
    "            print(f'{i}')\n",
    "            print('Population Total:', p)\n",
    "            print('Tested Total:', t)\n",
    "            print('Tested Percentage of Population:', tp, '%')\n",
    "            print('Cases Total:', c)\n",
    "            print('Active Cases:', a)\n",
    "            print('Confirmed Cases Percentage of Tested:', ct, '%')\n",
    "            print('Recoveries Total:', r)\n",
    "            print('Recoveries Percentage of Confirmed Cases:', rc, '%')\n",
    "            print('Deaths Total:', d)\n",
    "            print('Deaths Percentage of Confirmed Cases:', dc, '%')\n",
    "            print('Vaccinations:', v)\n",
    "            print('Vaccinations of Population:', vp, '%')\n",
    "            print('--------------------------------------')\n",
    "            ddd.loc[len(ddd.index)] = [f'{i}', p, t, tp, c, a, ct, r, rc, d, dc, v, vp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that prints a confusion matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_mat(y, y_pred):\n",
    "    print('\\nConfusion Matrix')\n",
    "    print('----------------')\n",
    "    cm=pd.DataFrame(confusion_matrix(y, y_pred))\n",
    "    print(cm)\n",
    "    plt.matshow(cm)\n",
    "    plt.title('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.colorbar()\n",
    "    cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that prints a classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Metrics(labels, preds):\n",
    "    actual_pos = labels == 1\n",
    "    actual_neg = labels == 0\n",
    "    tp = (preds == 1) & (actual_pos)\n",
    "    fp = (preds == 1) & (actual_neg)\n",
    "    tn = (preds == 0) & (actual_neg)\n",
    "    fn = (preds == 0) & (actual_pos)\n",
    "    precision=precision_score(labels, preds)\n",
    "    recall=recall_score(labels, preds)\n",
    "    f1=f1_score(labels, preds)\n",
    "    accuracy=accuracy_score(labels, preds)\n",
    "    specificity = sum(tn) / (sum(tn) + sum(fn))\n",
    "    print(\"Precision Score: {}\".format(precision))\n",
    "    print(\"Recall Score: {}\".format(recall))\n",
    "    print(\"F1 Score: {}\".format(f1))\n",
    "    print(\"Accuracy Score: {}\".format(accuracy))\n",
    "    print(\"Specificity Score: {}\".format(specificity))\n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(labels, preds)\n",
    "    plt.plot(lr_recall, lr_precision, marker='o')\n",
    "    plt.title('Precision Recall Tradeoff')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a function that prints roc auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc(y, y_hat):\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y, y_hat)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "    sns.set_style('darkgrid', {'axes.facecolor': '0.9'})\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    lw = 2\n",
    "    plt.plot(false_positive_rate, true_positive_rate, color='darkorange',\n",
    "             lw=lw, label='ROC curve')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.yticks([i/20.0 for i in range(21)])\n",
    "    plt.xticks([i/20.0 for i in range(21)])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    print('AUC: {}'.format(auc(false_positive_rate, true_positive_rate)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that prints muticlass metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass(model,x,y,y_hat,classes):\n",
    "    sort=sorted(set(classes))\n",
    "    for i,l,c in zip(y,y_hat,sort):\n",
    "        print(f'Class:{c}')\n",
    "        Metrics(i,l)\n",
    "        roc(i,l)\n",
    "        cv_score = cross_val_score(model, x, l, cv=5, scoring='roc_auc')\n",
    "        mean_cv_score = np.mean(cv_score)\n",
    "        print(f\"Cross Validated ROC AUC score: {mean_cv_score}\")\n",
    "        print('____________________________________________________')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that prints time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(dd, w, start, end, s, l, date1, date2, title):\n",
    "            date3=dd.index[0]\n",
    "            roll_mean = dd.rolling(window=w, center=False).mean()\n",
    "            roll_std = dd.rolling(window=w, center=False).std()\n",
    "            fig = plt.figure(figsize=(12,7))\n",
    "            plt.plot(dd, color='blue', label='Original')\n",
    "            plt.plot(roll_mean, color='red', label='Rolling Mean')\n",
    "            plt.plot(roll_std, color='black', label = 'Rolling Std')\n",
    "            plt.legend(loc='best')\n",
    "            plt.title(f'{title} Trend')\n",
    "            plt.show(block=False)\n",
    "            \n",
    "            dftest = adfuller(dd)\n",
    "            dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "            for key,value in dftest[4].items():\n",
    "                dfoutput['Critical Value (%s)'%key] = value\n",
    "            print (f'{title} Dickey-Fuller test results: \\n')\n",
    "            print(dfoutput)\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(16,3))\n",
    "            plot_acf(dd, ax=ax, lags=l)\n",
    "            plt.title(f'{title} autocorrelation')\n",
    "            plt.show()\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(16,3))\n",
    "            plot_pacf(dd, ax=ax, lags=l)\n",
    "            plt.title(f'{title} partial autocorrelation')\n",
    "            plt.show()\n",
    "            \n",
    "            print(f'{title} AIC Scores:')\n",
    "            # Define the p, d and q parameters to take any value between 0 and 2\n",
    "            p = d = q = range(0, 2)\n",
    "\n",
    "            # Generate all different combinations of p, d and q triplets\n",
    "            pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "            # Generate all different combinations of seasonal p, d and q triplets\n",
    "            pdqs = [(x[0], x[1], x[2], 7) for x in list(itertools.product(p, d, q))]\n",
    "            # Run a grid with pdq and seasonal pdq parameters calculated above and get the best AIC value\n",
    "            ans = []\n",
    "            for comb in pdq:\n",
    "                for combs in pdqs:\n",
    "                    try:\n",
    "                        mod = sm.tsa.statespace.SARIMAX(dd,\n",
    "                                                        order=comb,\n",
    "                                                        seasonal_order=combs,\n",
    "                                                        enforce_stationarity=False,\n",
    "                                                        enforce_invertibility=False)\n",
    "\n",
    "                        output = mod.fit()\n",
    "                        ans.append([comb, combs, output.aic])\n",
    "                        print('ARIMA {} x {}12 : AIC Calculated ={}'.format(comb, combs, output.aic))\n",
    "                    except:\n",
    "                        continue\n",
    "            # Find the parameters with minimal AIC value\n",
    "            ans_df = pd.DataFrame(ans, columns=['pdq', 'pdqs', 'aic'])\n",
    "            values=ans_df.loc[ans_df['aic'].idxmin()]\n",
    "            # Plug the optimal parameter values into a new SARIMAX model\n",
    "            ARIMA_MODEL = sm.tsa.statespace.SARIMAX(dd, \n",
    "                                                    order=values['pdq'], \n",
    "                                                    seasonal_order=values['pdqs'], \n",
    "                                                    enforce_stationarity=False, \n",
    "                                                    enforce_invertibility=False)\n",
    "\n",
    "            # Fit the model and print results\n",
    "            output = ARIMA_MODEL.fit()\n",
    "\n",
    "            print(f'{title} ARIMA:', output.summary())\n",
    "            \n",
    "            output.plot_diagnostics(figsize=(15, 18))\n",
    "            plt.show()\n",
    "\n",
    "            # Get predictions and calculate confidence intervals\n",
    "            pred = output.get_prediction(start=pd.to_datetime(date3), dynamic=False)\n",
    "            pred_conf = pred.conf_int()\n",
    "            \n",
    "            # Plot real vs predicted values along with confidence interval\n",
    "\n",
    "            # Plot observed values\n",
    "            ax = dd.plot(label='observed', figsize=(15, 18))\n",
    "\n",
    "            # Plot predicted values\n",
    "            pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=0.9)\n",
    "\n",
    "            # Plot the range for confidence intervals\n",
    "            ax.fill_between(pred_conf.index,\n",
    "                            pred_conf.iloc[:, 0],\n",
    "                            pred_conf.iloc[:, 1], color='g', alpha=0.5)\n",
    "\n",
    "            # Set axes labels\n",
    "            plt.title(f'{title} actual and predicted values with confidence interval')\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.set_ylabel(title)\n",
    "            plt.legend()\n",
    "\n",
    "            plt.show()\n",
    "            # Get the real and predicted values\n",
    "\n",
    "\n",
    "            forecasted = pred.predicted_mean\n",
    "            truth = dd\n",
    "            # Compute the mean square error\n",
    "            rmse=np.sqrt(mean_squared_error(truth, forecasted))\n",
    "            print(f'{title} Root Mean Squared Error:{round(rmse, 2)}')\n",
    "            \n",
    "            f=output.forecast(steps=s)\n",
    "            prediction = output.get_forecast(steps=s)\n",
    "            pred_conf_f = prediction.conf_int()\n",
    "            print(f'{title} Forecast:')\n",
    "            print(f)\n",
    "            start[title]=dd.iloc[-1]\n",
    "            end[title]=f.iloc[-1]\n",
    "            \n",
    "            # Plot future predictions with confidence intervals\n",
    "            ax = dd.plot(label='observed', figsize=(20, 15))\n",
    "            prediction.predicted_mean.plot(ax=ax, label='Forecast')\n",
    "            ax.fill_between(pred_conf_f.index,\n",
    "                            pred_conf_f.iloc[:, 0],\n",
    "                            pred_conf_f.iloc[:, 1], color='k', alpha=0.25)\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.set_ylabel(title)\n",
    "            plt.title(f'{title} trend and future predictions with confidence interval')\n",
    "\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that returns percentage change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pecentage_change(x1,x2):\n",
    "    c=((x2-x1)/x1)*100\n",
    "    return(f'Pecentage Change: {c}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
